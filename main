import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, ConcatDataset
import torchvision
from torchvision.datasets.mnist import MNIST
import numpy as np
import os
import time
import plotly.subplots as sp
import plotly.graph_objects as go
from model import NetConv
from evaluation import evaluate, evaluate_others

# 检查是否有可用的 GPU，否则使用 CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def save_model(model, optimizer, current_epoch):
    out = os.path.join("./save/checkpoint_{}.tar".format(current_epoch))
    state = {
        "net": model.state_dict(),
        "optimizer": optimizer.state_dict(),
        "epoch": current_epoch,
    }
    torch.save(state, out)


def inference():
    net.compute_cluster_center(alpha)
    net.eval()
    feature_vector = []
    labels_vector = []
    pred_vector = []
    with torch.no_grad():
        for step, (x, y) in enumerate(data_loader_test):
            x = x.to(device)
            z = net.encode(x)
            pred = net.predict(z)
            feature_vector.extend(z.detach().cpu().numpy())
            labels_vector.extend(y.numpy())
            pred_vector.extend(pred.detach().cpu().numpy())
    feature_vector = np.array(feature_vector)
    labels_vector = np.array(labels_vector)
    pred_vector = np.array(pred_vector)
    return feature_vector, labels_vector, pred_vector


def visualize_cluster_center():
    with torch.no_grad():
        cluster_center = net.compute_cluster_center(alpha)
        reconstruction = net.decode(cluster_center)

    # 创建子图布局，2行5列
    fig = sp.make_subplots(rows=2, cols=5, subplot_titles=[f"Center {i + 1}" for i in range(10)])

    for i in range(10):
        # 获取图像数据并调整格式
        if dataset[0][0].shape[0] == 1:  # MNIST 或灰度图像
            img = reconstruction[i].detach().cpu().numpy().reshape(28, 28)
            img = np.flipud(img)  # 进行图像的上下翻转
            fig.add_trace(go.Heatmap(z=img, colorscale='gray', showscale=True), row=(i // 5) + 1, col=(i % 5) + 1)
        else:  # CIFAR10 或 RGB 图像
            img = reconstruction[i].detach().cpu().numpy().transpose(1, 2, 0)
            img = np.flipud(img)  # 进行图像的上下翻转
            fig.add_trace(go.Image(z=img), row=(i // 5) + 1, col=(i % 5) + 1)

    # 更新布局
    fig.update_layout(height=600, width=1000, title_text="Cluster Center Visualization", showlegend=True)

    # 将图表保存为 HTML 格式，方便交互
    fig.write_html(f"./cluster_center_epoch_{epoch}.html")
    fig.show()


if __name__ == "__main__":
    seed = 1
    torch.manual_seed(seed)
    np.random.seed(seed)

    # 数据转换
    transforms = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
    ])

    # 加载 MNIST 数据集
    train_dataset = MNIST(
        root="./datasets", train=True, download=True, transform=transforms
    )
    test_dataset = MNIST(
        root="./datasets", train=False, download=True, transform=transforms
    )

    # 将训练集和测试集合并
    dataset = ConcatDataset([train_dataset, test_dataset])
    class_num = 10
    batch_size = 256

    # 定义数据加载器
    data_loader = DataLoader(
        dataset, batch_size=batch_size, shuffle=True, drop_last=True
    )
    data_loader_test = DataLoader(
        dataset, batch_size=500, shuffle=False, drop_last=False
    )

    # 初始化网络模型
    net = NetConv(channel=1, inner_dim=784, class_num=class_num).to(device)

    # 优化器和损失函数
    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)
    criterion = nn.MSELoss(reduction="mean")

    start_epoch = 0
    epochs = 3001
    alpha = 0.001
    gamma = 0.02

    net.normalize_cluster_center(alpha)

    time_start = time.perf_counter()

    for epoch in range(start_epoch, epochs):
        loss_clu_epoch = loss_rec_epoch = kld_epoch = 0
        net.train()

        for step, (x, y) in enumerate(data_loader):
            x = x.to(device)
            batchsz = x.shape[0]

            # 编码并进行聚类
            z = net.encode(x)
            if epoch % 2 == 1:
                cluster_batch = net.cluster(z)
            else:
                cluster_batch = net.cluster(z.detach())

            soft_label = F.softmax(cluster_batch.detach(), dim=1)
            delta = torch.zeros((batch_size, 10), device=device, requires_grad=False)
            for i in range(batch_size):
                delta[i, torch.argmax(soft_label[i, :])] = 1

            # 计算损失
            loss_clu_batch = 2 * alpha - torch.mul(delta, cluster_batch)
            loss_clu_batch = 0.01 / alpha * loss_clu_batch.mean()

            mu, sigma = torch.chunk(z, 2, 1)
            kld = 0.5 * torch.sum(mu ** 2 + sigma ** 2 - torch.log(1e-8 + sigma ** 2) - 1) / (batchsz * 28 * 28)
            if kld is not None:
                eb = -1.0 * kld
                kld = gamma * (- eb)

            x_ = net.decode(z)
            loss_rec = criterion(x, x_)
            loss_rec += kld

            loss = loss_rec + loss_clu_batch

            optimizer.zero_grad()
            loss.backward()

            # 更新聚类层的梯度
            if epoch % 2 == 0:
                net.cluster_layer.weight.grad = (
                        F.normalize(net.cluster_layer.weight.grad, dim=1) * 0.2 * alpha
                )
            else:
                net.cluster_layer.zero_grad()

            optimizer.step()
            net.normalize_cluster_center(alpha)

            loss_clu_epoch += loss_clu_batch.item()  # Clustering loss
            loss_rec_epoch += loss_rec.item()  # Reconstruction loss

        run_time = round(time.perf_counter() - time_start, 3)
        print(
            f"Epoch [{epoch}/{epochs}] Loss: {loss_rec_epoch / len(data_loader)} Clu Loss: {loss_clu_epoch / len(data_loader)}"
        )
        print('Elapsed Time:', run_time)

        if epoch % 50 == 0:
            feature, label, pred = inference()
            nmi, ari, acc = evaluate(label, pred)
            print(f"Model NMI = {nmi:.4f} ARI = {ari:.4f} ACC = {acc:.4f}")
            ami, homo, comp, v_mea = evaluate_others(label, pred)
            print(f"Model AMI = {ami:.4f} Homogeneity = {homo:.4f} Completeness = {comp:.4f} V_Measure = {v_mea:.4f}")
            save_model(net, optimizer, epoch)

        if epoch % 500 == 0:
            visualize_cluster_center()
